{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sriram0805/Summarize-YouTube-video-with-LLM/blob/main/Copy_of_Summarize_YouTube_video_with_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§ñ Tutorial: Summarize a Video with LLM\n",
        "This short tutorial will guide you through using the OpenAI API and a punctuation restoration model to summarize a YouTube video.\n",
        "\n",
        "üõ†Ô∏è Tools We Will Use:\n",
        "\n",
        "YouTube Transcript API: This will help us automatically generate subtitles from the YouTube video.\n",
        "Rpunct Library: We'll use this library to predict punctuation in the ASR transcript.\n",
        "OpenAI API: Specifically, we'll use GPT-3.5 Turbo for our task.\n",
        "These changes ensure that the text is grammatically correct and clearer for the reader.\n",
        "\n",
        "Author:Sriram"
      ],
      "metadata": {
        "id": "gNfhpjfBIo62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's start by installing the required packages."
      ],
      "metadata": {
        "id": "W4quwfCrX-IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "id": "5wGChlNonEi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/babthamotharan/rpunct.git@patch-2"
      ],
      "metadata": {
        "id": "Gf19aoVbb0KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "4eEv0G2FodhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's download the YouTube video\n",
        "Now, we will use YouTube API to download autmatically generated subtitles from videos (ASR transcripts)."
      ],
      "metadata": {
        "id": "cHiSZqubq30G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi"
      ],
      "metadata": {
        "id": "8zDHqqygnGkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_id(url_link):\n",
        "  return url_link.split(\"watch?v=\")[-1]"
      ],
      "metadata": {
        "id": "lJSspUDVnibp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_link = \"https://www.youtube.com/watch?v=IVfcAgxTO4I\""
      ],
      "metadata": {
        "id": "m3E1IPaXXD5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = YouTubeTranscriptApi.get_transcript(get_video_id(video_link))\n",
        "transcript_joined = \" \".join([line['text'] for line in transcript])"
      ],
      "metadata": {
        "id": "jBTs4wnBnH1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_joined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "ndVZI33On5cq",
        "outputId": "254bf17b-1b61-485e-c394-548a3354af58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"in this video we're going to look at a new package called embedging and this allows you to very easily create language model powered Bots over any data set in this introduction video we're going to show how to use this library but in future videos we're going to build some tools around embedging and I can elaborate more at the end of the video on what we might build but let's get started for now I have the embed chain GitHub repository open here and as you can see it's a framework to easily create llm-powered Bots over any data set and it abstracts the entire process of loading a data set chunking it and creating embeddings and then storing those embeddings in a vector database such as chroma DB and if we look at the code below here you can see that we have an app object that's being instantiated and then below that we are adding resources to that app object iteratively and each resource will give more context to your Bot that you're creating and you can add different resource types as you can see here for example YouTube videos PDF files and also web pages and once you've added your resources where what you can do is query the boat with a particular prompt and then you will get back a response and that response is coming from the language model on the back end which is the openai language model so embedchain provides a way to add these resources and it handles all of that process of embedding the text within those resources and then sending the request to open Ai and then getting the response that is informed by the content that you've added as resources so let's get started I'm going to go to visual studio code and we have here a main.pi file so you can create a python file where you can store the code that we're going to use in this video and it can be called anything you want and what I'm doing at the moment in the main.pi file is I'm using the python.in library and we're importing the function load.inf and we're calling that function on line four here and what that's going to do is it's going to load from our local dot end file the open AI API key so in order to use embedging you need to make sure you have that API key and that has to be stored in a dot in file and then you can use the python.in live library in order to load that into the operating system environment now on the terminal below here I have a virtual environment activated in Python what we can do is to get started we can actually install these libraries so we can install python dot end to start with and we can also install the embed chain Library as well once these are installed we can go back to our main.pi script and after we have loaded in the dot end file what we can do is from the embed chain Library we can import the app object and then we can create an app object by instantiating that and instead of calling it up I'm actually going to call this politics but we're going to create a bot that is informed of the political positions of the Republican and Democratic party in America and this is an apolitical video I'm not interested in either of these parties so let's start by learning how to add resources to the bot make sure here that I spill this correctly what I'm going to do is go to Wikipedia and we're just going to use that for Simplicity to start with later in the video I'm going to show how to load in a YouTube video and transcribe that and use that as part of your context here for the bot but for now I'm going to look at the political positions of the Republican party so let's copy the URL here at the top and we can go back to vs code and we're going to add the resource to our politics spot with the add function here and the first parameter to that is the type of resource that we're adding we're going to specify a web page here and the second parameter is the resource itself so we're going to paste the link to that Wikipedia article on the Republican party and there's a very similar page on Wikipedia for the Democratic party so we're going to add that just below the link to the Republican party so we have both of those Wikipedia Pages added to the context here we're adding them as resources for our bot and our bot is then going to take the text that it's extracting from those pages and it's going to store them in a vector database it's going to embed that text and store it in the underlying database and that is going to be used as context when we call the open EI models on the back end using the API so in order to call those models we need to use our politics Port here and we have a function called query and this is just going to take a prompt that we want to enter there so we're going to ask a question to the open AI model on the back end the language model and then we're going to get a response back and we can then use that response in our application so we're sending the request to the language model and we are sending also this context that we're adding to the bot and then we're getting back a response so let's start with this question what are the possessions of the political parties on same-sex marriage and we can store the response in a variable called answer and then after we've sent the query we can print that answer to the terminal in this case you can also output that to a streamline application if you're using streamlit or any other tools that are similar to that and then we can run this script with the python main.pi command and that is going to then send that request generate the response and print it to the terminal so let's see what happens here now to begin with what's happening is it's extracting the text from those web pages and on the top two lines here you can see that it's chunking them together and storing the chunks in the vector database now that's something to note about embedging if we go back to its documentation and scroll to the very bottom here you can see the tech stack that this Library uses under the hood so it's using Lang chain as an llm framework to load chunk and index the data it's using openai to create the embeddings that are stored in the vector database it's using the chat GPT API as the language model in order to get answers given the context and finally it's using chroma as the vector database to store the embeddings now if you're interested in Vector databases I'm thinking of doing a lot of videos on this so if you are interested in that let me know in the comments it's a very new thing so I'm also learning about that at the moment but very interesting topic so let me know if you're interested in some videos on that let's go back to our application now and you can see the answer that has been generated by the language model and it says here that the Democratic party generally supports same-sex marriage will the Republican party has historically been more divided on the issue but in recent years there has been a shift within the Republican party and a growing number of Republicans are in favor of same-sex marriage and as of 2017 a majority of Republicans were no longer opposed to same-sex marriage so it's taking this information from the context that we provided to the bot and in this case that context is two Wikipedia articles but you can provide much more than just two articles or two documents to the language model here and indeed if you provided more context the language model will have more to go on and it's likely to generate better responses and it's able to synthesize knowledge that's stored across multiple documents and multiple resources and give answers to questions and queries that involve the topics that are discussed in those documents so this is an example of getting a response from the language model let's change the prompt here and we're going to use a different one what are the possessions of the Republicans and the Democrats on climate change and environmental issues so let's clear the terminal at the bottom and rerun the main.pi script and this time at the top you can see that the Articles have already been embedded and they already exist in the data is the chunks that are generated from the text in those articles already exist in the database so it doesn't have to go through that embedding process again but below that you can see the output the Republicans assessment on the seriousness of climate change has remained essentially unchanged over the past decade on the other hand the Democrats have favored taking action to address the issue and as it says at the bottom the Democrats will acknowledge the threat and the Republicans are more skeptical in general so that's a response from the chatbot on this particular query let's add one more query here and then we'll move on so I'm going to paste another query in here what are both parties stances on taxation let's run the script again at the bottom and hopefully we'll get some output on this question and you can see the response at the bottom Republicans generally believe in lower tax rates particularly for those who create jobs and wealth Republicans also tend to pose the estate tax whatever that is Democrats on the other hand generally support higher tax rates especially for the wealthy in order to fund government programs and reduce income inequality so I think this bought based on just a simple Wikipedia article for each party is getting the general positions fairly correct for both parties on these issues and you can imagine the power of this if you added more context and you were able to ask more in-depth questions about the political opinions or possessions of these parties and this can be extended of course to any topic or any document you want to create a chat bot around or some sort of question answering tool around a set of information so let's move on and we're going to add some more resources to the context for this bot if we go back to the browser I have two pages open here on to American politicians we've got Ted Cruz and we also have Hillary Clinton and I'm only picking these two because well they're quite divisive politicians as far as I'm aware so let's go with this and add these to the context we're going to copy the URLs for both of these politicians and this is actually a site called rational Wiki I have no idea if this site is more left or right leaning and to be honest I don't really care about that so let's go back to vs code we're going to add these to the context at the bottom politicsport.add and again these are web pages we're going to see a YouTube example in a second and we'll paste that near the link to this article on Ted Cruz and we can copy that line of code below there and we can add the link to Hillary Clinton as well so let's remove this particular query that we're asking the Bots here and we're going to paste in a new one now let's ask our bot to sum up Ted Cruz in a few sentences so we'll clear the terminal and we can rerun the script now you can see as it's running through this we've added new resources so it's chunking those and adding them to the vector database and once they've been added to the vector database you can see the response from the openai language model below Ted Cruz is a conservative politician who gained prominence for his efforts to obstruct Obamacare he served as solicitor general of Texas before being elected as a senator and he's associated with the Tea Party Movement and known for his 21 hour speech against Obamacare so that's Ted Cruz in a few sentences apparently from the politics Port here let's now ask a very general question about Ted Cruz do people like Ted Cruz so let's clear the terminal here and run main.pi and see what the language model thinks about this question and the answer here is that based on a given context it can be inferred that both Republicans and Democrats have a strong dislike for Ted Cruz therefore it can be concluded that people in general do not like Ted Cruz quite a scathing assessment of Ted Cruz from embed chains bought here let's create one final prompt on the topic of Ted Cruz create three funny nicknames for Ted Cruz from the context so let's execute main.pi and we can see what we get back for this one and you can see the three nicknames at the bottom we've got flower squirter Ted we've got Ted the unlovable and we have spainless Ted so there's some nicknames for Ted Cruz let's now move on to asking some questions about Hillary Clinton let's replace the query that we're passing in here and we're gonna now sum up Hillary Clinton in a few sentences and we'll see what comes back from the language model for Hillary Clinton here and actually I'm getting back an error here it's a service unavailable error from open AIS API so it's saying that the server is overloaded and you might get these problems when you're calling the API at times this API I find it quite unreliable but that is of course due to the amount of people that are using it so hopefully as time goes on it can be more reliable let's try this again after giving it a couple of seconds break here and we have at the bottom a very simple description here of Hillary Clinton summed up in two sentences Hillary Clinton is an American politician and a member of the democratic party and she served as senator for New York and ran for president twice in 2008 and 2016 so it's getting that correct from the article we've added on Hillary Clinton let's add another query here on Hillary Clinton what issues do other Democrats have with Hillary Clinton let's run that script and we can see the output from the language model for this one and you can see the output at the bottom many Democrats have expressed dissatisfaction with Hillary Clinton's close ties to the finance industry particularly her relationship with Lloyd blankfein of Goldman Sachs there's also tension within the Democrats over her presidential bid with many anti-establishment Grassroots and left-leaning individuals expressing concerns about horror and other present-day plutonomists so that's some of the issues apparently with Hillary Clinton within the Democratic party itself let's now move on from these politicians and we're going to look at something a little bit different now we're going to look at how we can use a YouTube video as a resource for this book and I'm going to use this video here and this is a travel video it's the top 100 places to visit in Europe and this is by a guy called Ryan Shirley who's on YouTube doing a lot of travel videos we're gonna use the link for this video and we're going to bring it into our embed chain application so let's go back to the application and I'm going to remove all of this context that we've added and this time we're going to add a different type of resource it's going to be a YouTube video and again we provide the link to the video that we want to add now what Lang chain or rather what embed chain is going to do under the hood here is it's going to go to the link that we provide for the YouTube video and it's actually going to download the audio or it's going to transcribe that audio from audio to text and it's going to use tools provided by the line chain library in order to do that and line chain has these document loaders and there are document models for YouTube videos provided by launching again if you're interested in more content around that just let me know in the comments so what I'm going to do is remove this prompt that we've been using here I'm going to paste in another one which places are in Italy from this YouTube video now remember the YouTube video is about the top 100 places in the whole of Europe according to this guy at least so what we're going to do is we're going to try and find which places are in Italy that he recommends so let's try and run this again by running Python main.pi and we can see the output that's generated and you can see that what's happening with the YouTube video is it's chunking that video and it's saving those chunks to the database the vector database and below that we have the output of three or four places from Italy that are mentioned in his video on European travel destinations so I successfully extracted those Italian destinations from that YouTube video and we can look at other queries for example what places are in Scotland and you can see the output below Glencoe and the glenfinnin viaduct are both in Scotland and those are the two places he's visited in this video Let's quickly add two more queries that we're gonna use for this chatbot what we're going to ask here is if I love hiking and mountains where should I go in Europe when we run that we're hopefully going to get back some output with a useful suggestion based on the video content about where we can go if we want to go hiking or mountaineering and you can see that we have the answer provided Below based on the context provided you should consider visiting the Italian dolomites now I'm not going to read the rest of it what I'm going to do is add one more prompt to this chatbot and then we're going to finish the video now if you watch this guy's videos he loves to jump off cliffs into the ocean so what I'm going to ask is what places these are the best for cliff jumping let's clear the terminal and execute the script and you can see a couple of places mentioned including the island of ponza in Italy as places where cliff jumping is possible so you can see from this video how easy it is to add resources whether it's web pages or PDF films or YouTube videos to the context of an embed chain application and then generate a chat bot that's able to answer queries and questions based on that context now if you're interested in more videos on this what I'm thinking of doing is creating a streamline application that allows users to upload their own files and web pages and include them as part of the context and basically create their own chatbot around the resources that they have uploaded and then provide a prompt to allow them to query that chatbot and interact with it and if there's any interest I'm also thinking of creating a video where we build a chat bot in a web application with a backend that could be a Django backend or a fast API backend or even a go web application so thanks a lot for watching this video if you have any other ideas please let me know in the comments and if you've enjoyed the video please give it a thumbs up and subscribe to the channel and we'll see you in the next video\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add punctuation\n",
        "Because the original ASR transcripts do not have any punctuation, they are difficult to read. We will try to restore it. Additionally, LLMs usually expect that you provide text with punctuation. Providing text with no punctuation might result in errors."
      ],
      "metadata": {
        "id": "ATe9vOTbq_Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rpunct import RestorePuncts\n",
        "rpunct = RestorePuncts()"
      ],
      "metadata": {
        "id": "C61Sr9p7isKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = rpunct.punctuate(transcript_joined)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "pPsUiKv7C16w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9b9474-dd1b-4222-ad11-f1e3b1fea220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this video, we're going to look at a new package called Embedging and this allows you to very easily create language Model powered Bots over any data set. In this introduction video, we're going to show how to use this library, but in future videos, we're going to build some tools around embedging and I can elaborate more at the end of the video on what we might build. But let's get started for now: I have the embed chain GitHub Repository open here and as you can see, it's a framework to easily create Llm-powered Bots over any data set and it abstracts the entire process of loading a data set, chunking it, and creating embeddings, and then storing those embeddings in a vector database such as Chroma DB And if we look at the code below here, you can see that we have an app object that's being instantiated and then below that we are adding resources to that app object iteratively and each resource will give more context to your Bot that you're creating and you can add different resource types as you can see here. for example, YouTube videos, PDF files, and also web pages. And once you've added your resources where what you can do is query the boat with a particular prompt and then you will get back a response and that response is coming from the language model on the back end, which is the Openai language model. So Embedchain provides a way to add these resources and it handles all of that process of embedding the text within those resources and then sending the request to open Ai and then getting the response that is informed by the content that you've added as resources. So let's get started. I'm going to go to Visual Studio Code and we have here a Main.pi file. so you can create a Python file where you can store the code that we're going to use in this video and it can be called anything you want and what I'm doing at the moment in the Main.pi file is I'm using the Python.in Library and we're importing the function load.inf and we're calling that function on line Four here and what that's going to do is it's going to load from our local dot end file the Open AI API key. So in order to use embedging, you need to make sure you have that API key and that has to be stored in a dot in file and then you can use the Python.in Live Library in order to load that into the Operating system environment. Now on the terminal below here: I Have a virtual environment activated in Python What we can do is to get started. We can actually install these libraries so we can install Python dot End to start with and we can also install the embed chain Library as well. Once these are installed, we can go back to our Main.pi script and after we have loaded in the dot End file, what we can do is from the embed chain Library We can import the App object and then we can create an app object by instantiating that and instead of calling it up. I'm actually going to call this politics. but we're going to create a bot that is informed of the political positions of the Republican and Democratic party in America and this is an apolitical video. I'm not interested in either of these parties, so let's start by learning how to add resources to the bot. Make sure here that I spill this correctly. What I'm going to do is go to Wikipedia and we're just going to use that for Simplicity to start with later in the video. I'm going to show how to load in a YouTube video and transcribe that and use that as part of your context here for the bot. But for now, I'm going to look at the political positions of the Republican party. so let's copy the URL here at the top and we can go back to Vs code and we're going to add the resource to our politics spot with the add function here and the first parameter to that is the type of resource that we're adding. We're going to specify a web page here, and the second parameter is the resource itself. So we're going to paste the link to that Wikipedia article on the Republican party and there's a very similar page on Wikipedia for the Democratic party. so we're going to add that just below the link to the Republican party. So we have both of those Wikipedia Pages added to the context. Here, We're adding them as resources for our bot, and our bot is then going to take the text that it's extracting from those pages and it's going to store them in a vector database. It's going to embed that text and store it in the underlying database and that is going to be used as context when we call the Open EI models on the back end using the API. So in order to call those models, we need to use our politics Port here and we have a function called query and this is just going to take a prompt that we want to enter there. So we're going to ask a question to the Open AI model on the back end, the language model and then we're going to get a response back and we can then use that response in our application. So we're sending the request to the language model and we are sending also this context that we're adding to the bot and then we're getting back a response. So let's start with this question: what are the possessions of the political parties on same-sex marriage and we can store the response in a variable called answer and then after we've sent the query, we can print that answer to the terminal. In this case, you can also output that to a streamline application if you're using Streamlit or any other tools that are similar to that. And then we can run this script with the Python Main.pi command and that is going to then send that request, generate the response, and print it to the terminal. So let's see what happens here. Now to begin with what's happening is it's extracting the text from those web pages and on the top two lines here, you can see that it's chunking them together and storing the chunks in the vector database. Now that's something to note about embedging. If we go back to its documentation and scroll to the very bottom. here, you can see the tech stack that this Library uses under the hood. So it's using Lang Chain as an Llm framework to load, chunk, and index the data. It's using Openai to create the embeddings that are stored in the vector database. It's using the chat GPT API as the language model in order to get answers given the context. And finally, it's using Chroma as the vector database to store the embeddings. Now if you're interested in Vector databases, I'm thinking of doing a lot of videos on this, so if you are interested in that, let me know in the comments. it's a very new thing So I'm also learning about that at the moment. but very interesting topic so let me know if you're interested in some videos on that. Let's go back to our application now and you can see the answer that has been generated by the language model. And it says here that the Democratic party generally supports same-sex marriage will. The Republican party has historically been more divided on the issue, but in recent years there has been a shift within the Republican party and a growing number of Republicans are in favor of same-sex marriage. and as of 2017, a majority of Republicans were no longer opposed to same-sex marriage. So it's taking this information from the context that we provided to the bot. and in this case, that context is two Wikipedia articles. But you can provide much more than just two articles or two documents to the language model here. And indeed, if you provided more context, the language model will have more to go on and it's likely to generate better responses. And it's able to synthesize knowledge that's stored across multiple documents and multiple resources and give answers to questions and queries that involve the topics that are discussed in those documents. So this is an example of getting a response from the language model. Let's change the prompt here and we're going to use a different one. What are the possessions of the Republicans and the Democrats on climate change and environmental issues? So let's clear the terminal at the bottom and rerun the main.pi script and this time at the top you can see that the Articles have already been embedded and they already exist in the data is the chunks that are generated from the text in those articles already exist in the database, so it doesn't have to go through that embedding process again. But below that, you can see the output. The Republicans assessment on the seriousness of climate change has remained essentially unchanged over the past decade. On the other hand, the Democrats have favored taking action to address the issue and as it says at the bottom, the Democrats will acknowledge the threat and the Republicans are more skeptical in general. So that's a response from the chatbot on this particular query. Let's add one more query here and then we'll move on. So I'm going to paste another query in here. What are both parties stances on taxation? Let's run the script again at the bottom and hopefully we'll get some output on this question and you can see the response at the bottom. Republicans Generally believe in lower tax rates, particularly for those who create jobs and wealth. Republicans also tend to pose the estate tax, whatever that is. Democrats on the other hand, generally support higher tax rates, especially for the wealthy in order to fund government programs and reduce income inequality. So I Think this bought based on just a simple Wikipedia article for each party is getting the general positions fairly correct for both parties on these issues, and you can imagine the power of this if you added more context and you were able to ask more in-depth questions about the political opinions or possessions of these parties. And this can be extended of course, to any topic or any document you want to create a chat bot around or some sort of question answering tool around a set of information. So let's move on and we're going to add some more resources to the context for this bot if we go back to the browser: I Have two pages open here. on to American politicians. We've got Ted Cruz and we also have Hillary Clinton and I'm only picking these two because, well, they're quite divisive politicians as far as I'm aware. So let's go with this and add these to the context. We're going to copy the URLs for both of these politicians, and this is actually a site called Rational Wiki I Have no idea if this site is more left or right leaning and to be honest, I don't really care about that. So let's go back to Vs code. We're going to add these to the context at the bottom Politicsport.add and again these are web pages. We're going to see a YouTube example in a second and we'll paste that near the link to this article on Ted Cruz and we can copy that line of code below there and we can add the link to Hillary Clinton as well. So let's remove this particular query that we're asking the Bots here and we're going to paste in a new one. Now let's ask our bot to sum up Ted Cruz in a few sentences so we'll clear the terminal and we can rerun the script. Now you can see as it's running through this, we've added new resources, so it's chunking those and adding them to the vector database. And once they've been added to the vector database, you can see the response from the Openai language model below. Ted Cruz is a conservative politician who gained prominence for his efforts to obstruct Obamacare. He served as Solicitor General of Texas before being elected as a senator, and he's associated with the Tea Party Movement and known for his 21 hour speech against Obamacare. So that's Ted Cruz in a few sentences, apparently from the politics. Port Here, let's now ask a very general question about Ted Cruz. Do people like Ted Cruz? So let's clear the terminal here and run Main.pi and see what the language model thinks about this question. And the answer here is that based on a given context, it can be inferred that both Republicans and Democrats have a strong dislike for Ted Cruz. Therefore, it can be concluded that people in general do not like Ted Cruz. Quite a scathing assessment of Ted Cruz from embed chains bought here. Let's create one final prompt on the topic of Ted Cruz. Create three funny nicknames for Ted Cruz from the context. So let's execute Main.pi and we can see what we get back for this one. And you can see the three Nicknames at the bottom. We've got Flower Squirter Ted, We've got Ted The Unlovable and we have Spainless Ted So there's some nicknames for Ted Cruz. Let's now move on to asking some questions about Hillary Clinton. Let's replace the query that we're passing in here and we're gonna now sum up Hillary Clinton in a few sentences and we'll see what comes back from the language model for Hillary Clinton here. And actually I'm getting back an error here. It's a service unavailable error from open AIS API So it's saying that the server is overloaded and you might get these problems when you're calling the API at times. This API I find it quite unreliable, but that is of course due to the amount of people that are using it, so hopefully as time goes on it can be more reliable. Let's try this again. After giving it a couple of seconds break here and we have at the bottom a very simple description here of Hillary Clinton summed up in two sentences: Hillary Clinton is an American politician and a member of the Democratic party and she served as senator for New York and ran for president twice in 2008 and 2016. so it's getting that correct from the article we've added on Hillary Clinton. Let's add another query here on: Hillary Clinton What issues do other Democrats have with Hillary Clinton Let's run that script and we can see the output from the language model for this one and you can see the output at the bottom. Many Democrats have expressed dissatisfaction with Hillary Clinton's close ties to the finance industry, particularly her relationship with Lloyd Blankfein of Goldman Sachs. There's also tension within the Democrats over her presidential bid, with many anti-establishment Grassroots and left-leaning individuals expressing concerns about horror and other present-day plutonomists. So that's some of the issues apparently with Hillary Clinton within the Democratic party itself. Let's now move on from these politicians and we're going to look at something a little bit different. Now we're going to look at how we can use a YouTube video as a resource for this book. and I'm going to use this video here and this is a travel video. It's the top 100 places to visit in Europe and this is by a guy called Ryan Shirley who's on YouTube doing a lot of travel videos. We're gonna use the link for this video and we're going to bring it into our embed chain application. So let's go back to the application and I'm going to remove all of this context that we've added and this time we're going to add a different type of resource. It's going to be a YouTube video and again, we provide the link to the video that we want to add. Now what Lang chain or rather, what embed chain is going to do under the hood here is it's going to go to the link that we provide for the YouTube video and it's actually going to download the audio. or it's going to transcribe that audio from audio to text and it's going to use tools provided by the Line Chain library in order to do that. And Line Chain has these document loaders and there are document models for YouTube videos provided by launching again. If you're interested in more content around that, just let me know in the comments. So what I'm going to do is remove this prompt that we've been using here I'm going to paste in another one which places are in Italy from this YouTube video. Now remember, the YouTube video is about the top 100 places in the whole of Europe according to this guy at least. So what we're going to do is we're going to try and find which places are in Italy that he recommends. So let's try and run this again by running Python Main.pi and we can see the output that's generated and you can see that what's happening with the YouTube video is it's chunking that video and it's saving those chunks to the database, the vector database and below that we have the output of three or four places from Italy that are mentioned in his video on European travel destinations. So I successfully extracted those Italian destinations from that YouTube video and we can look at other queries for example, what places are in Scotland and you can see the output below Glencoe and the Glenfinnin Viaduct are both in Scotland and those are the two places he's visited in this video. Let's quickly add two more queries that we're gonna use for this chatbot. What we're going to ask here is if: I Love hiking and mountains where should I go in Europe When we run that, we're hopefully going to get back some output with a useful suggestion based on the video content about where we can go if we want to go hiking or mountaineering and you can see that we have the answer provided Below Based on the context provided, you should consider visiting the Italian dolomites now. I'm not going to read the rest of it. What I'm going to do is add one more prompt to this chatbot and then we're going to finish the video. Now if you watch this guy's videos, he loves to jump off cliffs into the ocean. So what I'm going to ask is what places these are the best for cliff jumping. Let's clear the terminal and execute the script and you can see a couple of places mentioned including the island of Ponza in Italy as places where cliff jumping is possible. So you can see from this video how easy it is to add resources whether it's web pages or PDF films or YouTube videos to the context of an embed chain application and then generate a chat bot that's able to answer queries and questions based on that context. Now if you're interested in more videos on this, What I'm thinking of doing is creating a streamline application that allows users to upload their own files and web pages and include them as part of the context and basically create their own chatbot around the resources that they have uploaded and then provide a prompt to allow them to query that chatbot and interact with it. And if there's any interest. I'm also thinking of creating a video where we build a chat bot in a web application with a backend that could be a Django backend or a fast API backend or even a Go web application. So thanks a lot for watching this video. If you have any other ideas, please let me know in the comments and if you've enjoyed the video, please give it a thumbs up and subscribe to the channel and we'll see you in the next video.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**The text with predicted punctuation:**\n",
        "\n",
        "In this video, we're going to look at a new package called Embedging and this allows you to very easily create language Model powered Bots over any data set. In this introduction video, we're going to show how to use this library, but in future videos, we're going to build some tools around embedging and I can elaborate more at the end of the video on what we might build. But let's get started for now: I have the embed chain GitHub Repository open here and as you can see, it's a framework to easily create Llm-powered Bots over any data set and it abstracts the entire process of loading a data set, chunking it, and creating embeddings, and then storing those embeddings in a vector database such as Chroma DB And if we look at the code below here, yBot that you're creating and you can add different resource types as you can see here. for example, YouTube videos, PDF files, and also web pages. (...)\n"
      ],
      "metadata": {
        "id": "zt5vmbOuZx03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query OpenAI Gpt-3.5 Turbo (ChatGPT 3.5)\n",
        "Finally we can ask OpenAI model to summarize tekst, ask questions or to even write a blog post about this video."
      ],
      "metadata": {
        "id": "wzM3rOUanRQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "istW2Bhdp2f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to add you api token. Here's how to find it:\n",
        "\n",
        "1.   Visit the OpenAI website at https://www.openai.com and log in.\n",
        "2. Once logged in, navigate to your account settings. Look for the \"API Tokens\" section.\n",
        "3. Generate a new API token if you don't have one, or copy your existing API token.\n",
        "\n",
        "You'll ensure that you have the necessary access to use the OpenAI API for your video summarization task. üóùÔ∏èüîê"
      ],
      "metadata": {
        "id": "WgUeeL3HcDVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"sk-your-api-token\""
      ],
      "metadata": {
        "id": "Jp59RFWTqK8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a prompt of your choice"
      ],
      "metadata": {
        "id": "acYBMca1cpq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'\"Summarize this text: \\ntext = \"{transcript_joined}\"'"
      ],
      "metadata": {
        "id": "TIZ6bQ3D8Ofi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can query the model. We will use ChatCompletion query type to make it work like ChatGPT."
      ],
      "metadata": {
        "id": "gkHXetYbcsMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a chat completion request using OpenAI API\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",   # Role of the message sender (user or assistant)\n",
        "      \"content\": prompt  # Content of the message (user's input or assistant's reply)\n",
        "    }\n",
        "  ],\n",
        "  temperature=1, # Temperature controls randomness in the response\n",
        "  max_tokens=256, # Maximum number of tokens in the response\n",
        "  top_p=1, # Top-p (nucleus) sampling parameter, higher values make output more focused\n",
        "  frequency_penalty=0, # Frequency penalty discourages the model from repeating words or phrases\n",
        "  presence_penalty=0 # Presence penalty discourages the model from adding verbose or unnecessary words\n",
        ")\n"
      ],
      "metadata": {
        "id": "wTJA3chSU353"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Ww7WWWwXPX",
        "outputId": "974dd46c-1c6a-48a0-d007-394755087333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is a detailed explanation of how to use the embed chain package to create language model-powered Bots. The author walks through the process of adding resources to the bot, querying the language model, and obtaining responses based on the provided context. The author demonstrates using web pages, YouTube videos, and a transcribed travel video as resources for the bot. The text also mentions the use of the openai language model and the chroma vector database. The author suggests potential future videos on vector databases and building a chatbot in a web application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generated summary:** The text is a detailed explanation of how to use the embed chain package to create language model-powered Bots. The author walks through the process of adding resources to the bot, querying the language model, and obtaining responses based on the provided context. The author demonstrates using web pages, YouTube videos, and a transcribed travel video as resources for the bot. The text also mentions the use of the openai language model and the chroma vector database. The author suggests potential future videos on vector databases and building a chatbot in a web application.\n"
      ],
      "metadata": {
        "id": "tgPLdb9HWtZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you prefer you can summarize text in different formats"
      ],
      "metadata": {
        "id": "RaPmSGnfbAsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'\"Summarize this text using bulletpoints: \\ntext = \"{transcript_joined}\"'"
      ],
      "metadata": {
        "id": "CTJt10CRT0Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "7nK5DFo4U_Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCzBDQPvVBFe",
        "outputId": "152c5bdc-9e78-40d6-bba2-3e2083e61cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- The text discusses a new package called \"embedchain\" that allows users to create language model powered bots over any dataset.\n",
            "- The package helps with loading datasets, creating embeddings, and storing them in a vector database.\n",
            "- The code demonstrates how to add resources to the bot, such as web pages, YouTube videos, and PDF files.\n",
            "- Users can query the bot with a prompt and receive a response generated by the language model.\n",
            "- The text mentions the use of the OpenAI language model and the importance of having an API key stored in a .env file.\n",
            "- The author suggests installing the python-dotenv and embedchain libraries and using Visual Studio Code to run the code.\n",
            "- Examples of queries and responses are provided, such as asking about the political positions on same-sex marriage, climate change, and taxation.\n",
            "- The author then adds more resources, including Wikipedia articles on political parties and two web pages on American politicians.\n",
            "- Queries about Ted Cruz and Hillary Clinton are made, and responses are generated based on the added context.\n",
            "- The author also demonstrates how to add a YouTube video as a resource and queries about travel destinations in Europe are made.\n",
            "- The bot successfully extracts information from the video and provides answers based on the context.\n",
            "- The text concludes by mentioning potential future\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generated summary in bullet points:**\n",
        "- The text discusses a new package called \"embedchain\" that allows users to create language model powered bots over any dataset.\n",
        "- The package helps with loading datasets, creating embeddings, and storing them in a vector database.\n",
        "- The code demonstrates how to add resources to the bot, such as web pages, YouTube videos, and PDF files.\n",
        "- Users can query the bot with a prompt and receive a response generated by the language model.\n",
        "- The text mentions the use of the OpenAI language model and the importance of having an API key stored in a .env file.\n",
        "- The author suggests installing the python-dotenv and embedchain libraries and using Visual Studio Code to run the code.\n",
        "- Examples of queries and responses are provided, such as asking about the political positions on same-sex marriage, climate change, and taxation.\n",
        "- The author then adds more resources, including Wikipedia articles on political parties and two web pages on American politicians.\n",
        "- Queries about Ted Cruz and Hillary Clinton are made, and responses are generated based on the added context.\n",
        "- The author also demonstrates how to add a YouTube video as a resource and queries about travel destinations in Europe are made.\n",
        "- The bot successfully extracts information from the video and provides answers based on the context.\n",
        "- The text concludes by mentioning potential future\n"
      ],
      "metadata": {
        "id": "HNux8FQHaWrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can also ask questions"
      ],
      "metadata": {
        "id": "anpZ3fWGa8h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'\"What is embedchain? Provide concise yet detailed answer useing this information: \\ntext = \"{transcript_joined}\"'\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MXeFgqmWW6t",
        "outputId": "63cf1399-00a3-455f-f051-59a9bf9dcb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedchain is a package that allows users to create language model powered Bots over any dataset. It simplifies the process of loading a dataset, chunking it, creating embeddings, and storing those embeddings in a vector database. The package abstracts the entire process and provides an easy-to-use framework for creating Bots. It supports various resource types such as web pages, YouTube videos, and PDF files. Once resources are added, users can query the Bot with a prompt and receive a response from the language model on the backend, which is powered by the OpenAI language model. Embedchain handles the process of embedding the text within the resources, sending requests to OpenAI, and obtaining responses informed by the added context. With additional context, the language model can generate more accurate and informative responses. Embedchain offers flexibility and enables users to create chatbots or question-answering tools around any dataset or topic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generated answer:**\n",
        "\"Embedchain is a package that allows users to create language model powered Bots over any dataset. It simplifies the process of loading a dataset, chunking it, creating embeddings, and storing those embeddings in a vector database. The package abstracts the entire process and provides an easy-to-use framework for creating Bots. It supports various resource types such as web pages, YouTube videos, and PDF files. Once resources are added, users can query the Bot with a prompt and receive a response from the language model on the backend, which is powered by the OpenAI language model. Embedchain handles the process of embedding the text within the resources, sending requests to OpenAI, and obtaining responses informed by the added context. With additional context, the language model can generate more accurate and informative responses. Embedchain offers flexibility and enables users to create chatbots or question-answering tools around any dataset or topic.\n",
        "\""
      ],
      "metadata": {
        "id": "LLVqFvZeWmx2"
      }
    }
  ]
}